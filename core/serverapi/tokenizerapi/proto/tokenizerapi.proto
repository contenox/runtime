syntax = "proto3";

package tokenizerservicepb;

option go_package = "github.com/contenox/runtime-mvp/core/serverapi/tokenizerapi/proto";

import "google/protobuf/empty.proto";

// The main service definition.
service TokenizerService {
  // Tokenizes a given prompt using a specified model.
  rpc Tokenize(TokenizeRequest) returns (TokenizeResponse);

  // Counts the number of tokens in a given prompt for a specified model.
  rpc CountTokens(CountTokensRequest) returns (CountTokensResponse);

  // Lists the names of models currently available to the tokenizer.
  rpc AvailableModels(google.protobuf.Empty) returns (AvailableModelsResponse);

  // Determines the optimal tokenizer model to use based on a base model name.
  rpc OptimalModel(OptimalModelRequest) returns (OptimalModelResponse);

  // rpc AddModel(AddModelRequest) returns (google.protobuf.Empty);
  // rpc RemoveModel(RemoveModelRequest) returns (google.protobuf.Empty);
  // rpc ReplaceAllModels(ReplaceAllModelsRequest) returns (google.protobuf.Empty);
  // rpc SetAuthToken(SetAuthTokenRequest) returns (google.protobuf.Empty);
  // rpc SetFallbackModel(SetFallbackModelRequest) returns (google.protobuf.Empty);
  // rpc SetPreloadModels(SetPreloadModelsRequest) returns (google.protobuf.Empty);

}

// Request for the Tokenize RPC.
message TokenizeRequest {
  string model_name = 1; // The name of the model to use for tokenization.
  string prompt = 2;     // The text prompt to tokenize.
}

// Response for the Tokenize RPC.
message TokenizeResponse {
  repeated int32 tokens = 1; // The resulting token IDs.
}

// Request for the CountTokens RPC.
message CountTokensRequest {
  string model_name = 1; // The name of the model to use for counting tokens.
  string prompt = 2;     // The text prompt whose tokens are to be counted.
}

// Response for the CountTokens RPC.
message CountTokensResponse {
  int32 count = 1; // The total number of tokens.
}

// Response for the AvailableModels RPC.
message AvailableModelsResponse {
  repeated string model_names = 1; // List of available model names.
}

// Request for the OptimalModel RPC.
message OptimalModelRequest {
  string base_model = 1; // The base model name to find an optimal tokenizer for.
}

// Response for the OptimalModel RPC.
message OptimalModelResponse {
  string optimal_model_name = 1; // The name of the optimal tokenizer model found.
}

/*
message AddModelRequest {
  string name = 1;
  string url = 2;
}

message RemoveModelRequest {
  string name = 1;
}

message ReplaceAllModelsRequest {
  map<string, string> models = 1;
}

message SetAuthTokenRequest {
  string token = 1;
}

message SetFallbackModelRequest {
  string name = 1;
}

message SetPreloadModelsRequest {
  repeated string models = 1;
}
*/
